{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edgarbc/audio_transcriber/blob/main/my_audio_transcriber_whisper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jfTOrENATVvK"
      },
      "source": [
        "# My audio transcriber\n",
        "\n",
        "Audio automated transcriber using whisper from openAI.\n",
        "\n",
        "Whisper is an encoder-decoder auto-regressive model which was trained on audio translation and transcription tasks. Given audio data, the model is able to generate the corresponding text.\n",
        "\n",
        "by Edgar Bermudez - edgar.bermudez@gmail.com\n",
        "\n",
        "November, 2022."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMXx1rP4M5IL"
      },
      "source": [
        "For this example the audio files to be transcribed are previously uploaded to googgle drive. However, this example could be extended to have an interface to upload files and be transcribed directly (e.g. using gradio). I left a short example of how to use gradio for this at the end of the notebook. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qovECEDW--ar",
        "outputId": "89f95782-c36d-4e4d-e212-dc53dbb351b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ],
      "source": [
        "# to handle audio files\n",
        "!pip install pydub\n",
        "from pydub import AudioSegment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvMrQ-CoD89v",
        "outputId": "b7641343-f698-4e70-8923-31fb42dec062"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-f2f54cjn\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-f2f54cjn\n",
            "  Resolved https://github.com/openai/whisper.git to commit 7858aa9c08d98f75575035ecd6481f462d66ca27\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (1.21.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (1.13.1+cu116)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (4.64.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.8/dist-packages (from openai-whisper==20230124) (9.0.0)\n",
            "Collecting transformers>=4.19.0\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpeg-python==0.2.0\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from ffmpeg-python==0.2.0->openai-whisper==20230124) (0.16.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (2.25.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->openai-whisper==20230124) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->openai-whisper==20230124) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->openai-whisper==20230124) (2022.12.7)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20230124-py3-none-any.whl size=1179424 sha256=ec91605ad295510d81fce148f8f4de62af6b7845f31c2c6d3b2a79efd88def86\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-peh298kd/wheels/a7/70/18/b7693c07b1d18b3dafb328f5d0496aa0d41a9c09ef332fd8e6\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tokenizers, ffmpeg-python, huggingface-hub, transformers, openai-whisper\n",
            "Successfully installed ffmpeg-python-0.2.0 huggingface-hub-0.12.1 openai-whisper-20230124 tokenizers-0.13.2 transformers-4.26.1\n"
          ]
        }
      ],
      "source": [
        "# install whisper\n",
        "!pip install git+https://github.com/openai/whisper.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UI9yrzAG-1DJ",
        "outputId": "9594f654-6201-4b16-d346-1f84a957777b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# in order to access audio files (previously saved into google drive), we mount it\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TOi4q-K988SO"
      },
      "outputs": [],
      "source": [
        "# to handle files easily\n",
        "from glob import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrw0FwiBBJan",
        "outputId": "26e15650-a1ef-47dd-81c6-d93d2a45b41c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████| 139M/139M [00:00<00:00, 146MiB/s]\n"
          ]
        }
      ],
      "source": [
        "# load whisper \n",
        "import whisper\n",
        "# load model. Check for other models\n",
        "model = whisper.load_model(\"base\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-xf6-KFWXKS"
      },
      "source": [
        "Parameters and definitions "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1aGso1LEvUi",
        "outputId": "4fe42d9a-d0f8-49d3-88be-d737a41b1732"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "drive/MyDrive/BaileyAndSoda/data/\n"
          ]
        }
      ],
      "source": [
        "data_dir = 'drive/MyDrive/data/'\n",
        "sound_file = 'example_audio.WAV'\n",
        "print(data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9TQPQV_XIkz",
        "outputId": "a672c58f-1f62-45ef-fadd-8f34afb9338f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "# make sure we are in the right place\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uU5eUvsJA8YP"
      },
      "source": [
        "## Load audio file\n",
        "\n",
        "Assumes that audio files are saved into google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ezT5dQI0-21x"
      },
      "outputs": [],
      "source": [
        "\n",
        "#importing file from location by giving its path (for mp3 and wav)\n",
        "\n",
        "#sound = AudioSegment.from_mp3(data_dir + sound_file)\n",
        "sound = AudioSegment.from_file(file = data_dir + sound_file, format = \"wav\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP_g5zL1_8-W"
      },
      "source": [
        "## Audio File slicing\n",
        "\n",
        "Slice the audio file into 10 min (approx) segments,  transcribe them and save them into text files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eR8GNdQsAsym",
        "outputId": "1dbd7764-c7fd-4128-dc03-af698b1b7b27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total duration (mins): 73.2\n"
          ]
        }
      ],
      "source": [
        "# total time in mins of the file\n",
        "total_mins = sound.duration_seconds/60\n",
        "print('total duration (mins): ' + str(total_mins))\n",
        "\n",
        "slice_size = 10 # slice size (mins)\n",
        "\n",
        "num_slices = int(total_mins / slice_size) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sM6UGA6QnQEx",
        "outputId": "5654c987-0852-4e8b-fcce-6e71783aa031"
      },
      "outputs": [],
      "source": [
        "\n",
        "interval = 10\n",
        "offset = 20\n",
        "\n",
        "for i in range(num_slices):\n",
        "\n",
        "  if (i==0):\n",
        "    start_time = 1000 * ((i * interval * 60))\n",
        "  else:   \n",
        "    start_time = 1000 * ((i * interval * 60) - offset) \n",
        "  end_time = 1000 * ((i+1) * interval * 60)\n",
        "  print(start_time)\n",
        "  print(end_time)   \n",
        "  # take the corresponding slice\n",
        "  sound_slice = sound[start_time:end_time]\n",
        "\n",
        "  # create a file name\n",
        "  fname = 'slice_'+str(i) + '.mp3'\n",
        "  print(data_dir + fname)\n",
        "  # save it to file \n",
        "  sound_slice.export(data_dir + fname, format='mp3')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVepX2MD9H2C",
        "outputId": "98643fb8-1150-4c75-d34a-0daa7838b328"
      },
      "outputs": [],
      "source": [
        "# Only with very large files (more than 2 hours is necessary to \n",
        "# slice it).\n",
        "\n",
        "#slice_files = glob(data_dir + '*.mp3')\n",
        "slice_files = glob(data_dir + '*.WAV')\n",
        "print(slice_files)\n",
        "\n",
        "num_slices = len(slice_files)\n",
        "# transcribe each of the audio segments\n",
        "for slice_file in range(num_slices):\n",
        "  result = model.transcribe(slice_files[slice_file])\n",
        "\n",
        "  text_fname = slice_files[slice_file][:-4] + '.txt'\n",
        "  text_file = open(text_fname, \"w\")\n",
        "  n = text_file.write(result['text'])\n",
        "  text_file.close()\n",
        "  print(text_fname + ' transcribed!') \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "id": "DlB9iGykTtX0",
        "outputId": "5d720be2-bcd7-4319-a595-f8c6c26e1ad5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "\n",
            "Using Embedded Colab Mode (NEW). If you have issues, please use share=True and file an issue at https://github.com/gradio-app/gradio/\n",
            "Note: opening the browser inspector may crash Embedded Colab Mode.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "application/javascript": "(async (port, path, width, height, cache, element) => {\n                        if (!google.colab.kernel.accessAllowed && !cache) {\n                            return;\n                        }\n                        element.appendChild(document.createTextNode(''));\n                        const url = await google.colab.kernel.proxyPort(port, {cache});\n\n                        const external_link = document.createElement('div');\n                        external_link.innerHTML = `\n                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n                                    https://localhost:${port}${path}\n                                </a>\n                            </div>\n                        `;\n                        element.appendChild(external_link);\n\n                        const iframe = document.createElement('iframe');\n                        iframe.src = new URL(path, url).toString();\n                        iframe.height = height;\n                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n                        iframe.width = width;\n                        iframe.style.border = 0;\n                        element.appendChild(iframe);\n                    })(7860, \"/\", \"100%\", 500, false, window.element)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "(<gradio.routes.App at 0x7f73edf43bd0>, 'http://127.0.0.1:7860/', None)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# example using gradio\n",
        "# TODO: expand and improve\n",
        "from transformers import pipeline\n",
        "import gradio as gr\n",
        "\n",
        "pipe = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-small\")\n",
        "\n",
        "def inference(speech_file):\n",
        "  return pipe(speech_file)[\"text\"]\n",
        "\n",
        "gr.Interface(inference,gr.Audio(type=\"filepath\"),\"text\").launch()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "oraq_local",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "d35cce6128368a4a1cf50723251fb8ed69646c4721e7d12f126c0d125fa8c524"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
