{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edgarbc/audio_transcriber/blob/main/my_audio_transcriber_whisper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# My audio transcriber\n",
        "\n",
        "Audio automated transcriber using whisper from openAI.\n",
        "\n",
        "by Edgar Bermudez - edgar.bermudez@gmail.com\n",
        "\n",
        "November, 2022."
      ],
      "metadata": {
        "id": "jfTOrENATVvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to handle audio files\n",
        "!pip install pydub\n",
        "from pydub import AudioSegment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qovECEDW--ar",
        "outputId": "16a5fe15-acc8-44c3-fd52-ecc24d6422ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install whisper\n",
        "!pip install git+https://github.com/openai/whisper.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvMrQ-CoD89v",
        "outputId": "726c07d0-0cd4-4338-db04-1b4ce1c5f06b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-wg8vpt2g\n",
            "  Running command git clone -q https://github.com/openai/whisper.git /tmp/pip-req-build-wg8vpt2g\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from whisper==1.0) (1.21.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from whisper==1.0) (1.12.1+cu113)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from whisper==1.0) (4.64.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.8/dist-packages (from whisper==1.0) (9.0.0)\n",
            "Collecting transformers>=4.19.0\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 5.1 MB/s \n",
            "\u001b[?25hCollecting ffmpeg-python==0.2.0\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from ffmpeg-python==0.2.0->whisper==1.0) (0.16.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 51.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 74.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers>=4.19.0->whisper==1.0) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers>=4.19.0->whisper==1.0) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers>=4.19.0->whisper==1.0) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers>=4.19.0->whisper==1.0) (3.0.4)\n",
            "Building wheels for collected packages: whisper\n",
            "  Building wheel for whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for whisper: filename=whisper-1.0-py3-none-any.whl size=1175239 sha256=5a5906645e058a0c0038defdcf69ceb8e315b56f013a4d28c8119e386ff729fb\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-v7homayd/wheels/a7/70/18/b7693c07b1d18b3dafb328f5d0496aa0d41a9c09ef332fd8e6\n",
            "Successfully built whisper\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers, ffmpeg-python, whisper\n",
            "Successfully installed ffmpeg-python-0.2.0 huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1 whisper-1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# in order to access audio files (previously saved into google drive), we mount it\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UI9yrzAG-1DJ",
        "outputId": "4693193b-0de5-4604-e610-5c609f4f6065"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob"
      ],
      "metadata": {
        "id": "TOi4q-K988SO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "model = whisper.load_model(\"base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrw0FwiBBJan",
        "outputId": "1017697c-5e1e-4a5b-ee68-cf95342af1a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:03<00:00, 47.6MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameters and definitions "
      ],
      "metadata": {
        "id": "t-xf6-KFWXKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = 'drive/MyDrive/BaileyAndSoda/data/'\n",
        "sound_file = 'ZOOM_13DEC2021_LR.WAV'\n",
        "print(data_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1aGso1LEvUi",
        "outputId": "24bb5df4-9501-492f-f184-8bc55677178b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive/MyDrive/BaileyAndSoda/data/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make sure we are in the right place\n",
        "!pwd\n",
        "!ls -lah 'drive/MyDrive/BaileyAndSoda/data/'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9TQPQV_XIkz",
        "outputId": "544b714a-a8cf-4857-bf8c-cb2e8987ad17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "total 1.3G\n",
            "-rw------- 1 root root  43M Dec  3 18:20 MZ000003.WAV\n",
            "-rw------- 1 root root 317M Dec  3 18:20 MZ000004.WAV\n",
            "-rw------- 1 root root 143M Dec  3 18:20 MZ000005.WAV\n",
            "-rw------- 1 root root  69M Dec  3 18:20 MZ000006.WAV\n",
            "-rw------- 1 root root 168M Dec  3 18:21 MZ000007.WAV\n",
            "-rw------- 1 root root  46M Dec  3 18:21 MZ000008.WAV\n",
            "-rw------- 1 root root 454M Dec  3 18:21 MZ000009.WAV\n",
            "-rw------- 1 root root  57M Dec  3 18:21 MZ000010.WAV\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load audio file\n",
        "\n",
        "Assumes that audio files are saved into google drive"
      ],
      "metadata": {
        "id": "uU5eUvsJA8YP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#importing file from location by giving its path\n",
        "sound = AudioSegment.from_mp3(data_dir + sound_file)\n"
      ],
      "metadata": {
        "id": "ezT5dQI0-21x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Audio File slicing\n",
        "\n",
        "Slice the audio file into 10 min (approx) segments,  transcribe them and save them into text files."
      ],
      "metadata": {
        "id": "LP_g5zL1_8-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# total time in mins of the file\n",
        "total_mins = sound.duration_seconds/60\n",
        "print('total duration (mins): ' + str(total_mins))\n",
        "\n",
        "slice_size = 10 # slice size (mins)\n",
        "\n",
        "num_slices = int(total_mins / slice_size) + 1"
      ],
      "metadata": {
        "id": "eR8GNdQsAsym",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e775916-a38e-428b-a880-1ed2b251678b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total duration (mins): 71.19170370370371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "interval = 10\n",
        "offset = 20\n",
        "\n",
        "for i in range(num_slices):\n",
        "\n",
        "  if (i==0):\n",
        "    start_time = 1000 * ((i * interval * 60))\n",
        "  else:   \n",
        "    start_time = 1000 * ((i * interval * 60) - offset) \n",
        "  end_time = 1000 * ((i+1) * interval * 60)\n",
        "  print(start_time)\n",
        "  print(end_time)   \n",
        "  # take the corresponding slice\n",
        "  sound_slice = sound[start_time:end_time]\n",
        "\n",
        "  # create a file name\n",
        "  fname = 'slice_'+str(i) + '.mp3'\n",
        "  print(data_dir + fname)\n",
        "  # save it to file \n",
        "  sound_slice.export(data_dir + fname, format='mp3')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sM6UGA6QnQEx",
        "outputId": "f2f10399-0a2c-43b5-e9ed-2726bbc98f26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "600000\n",
            "drive/MyDrive/BaileyAndSoda/data/slice_0.mp3\n",
            "580000\n",
            "1200000\n",
            "drive/MyDrive/BaileyAndSoda/data/slice_1.mp3\n",
            "1180000\n",
            "1800000\n",
            "drive/MyDrive/BaileyAndSoda/data/slice_2.mp3\n",
            "1780000\n",
            "2400000\n",
            "drive/MyDrive/BaileyAndSoda/data/slice_3.mp3\n",
            "2380000\n",
            "3000000\n",
            "drive/MyDrive/BaileyAndSoda/data/slice_4.mp3\n",
            "2980000\n",
            "3600000\n",
            "drive/MyDrive/BaileyAndSoda/data/slice_5.mp3\n",
            "3580000\n",
            "4200000\n",
            "drive/MyDrive/BaileyAndSoda/data/slice_6.mp3\n",
            "4180000\n",
            "4800000\n",
            "drive/MyDrive/BaileyAndSoda/data/slice_7.mp3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "slice_files = glob(data_dir + '*.mp3')\n",
        "print(slice_files)\n",
        "\n",
        "num_slices = len(slice_files)\n",
        "\n",
        "for slice_file in range(num_slices):\n",
        "  result = model.transcribe(slice_files[slice_file])\n",
        "\n",
        "  text_fname = slice_files[slice_file][:-4] + '.txt'\n",
        "  text_file = open(text_fname, \"w\")\n",
        "  n = text_file.write(result['text'])\n",
        "  text_file.close()\n",
        "  print(text_fname + ' transcribed!') \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVepX2MD9H2C",
        "outputId": "565148ce-c279-4908-9004-d3f0d11caf62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['drive/MyDrive/BaileyAndSoda/data/slice_0.mp3', 'drive/MyDrive/BaileyAndSoda/data/slice_1.mp3', 'drive/MyDrive/BaileyAndSoda/data/slice_2.mp3', 'drive/MyDrive/BaileyAndSoda/data/slice_3.mp3', 'drive/MyDrive/BaileyAndSoda/data/slice_4.mp3', 'drive/MyDrive/BaileyAndSoda/data/slice_5.mp3', 'drive/MyDrive/BaileyAndSoda/data/slice_6.mp3', 'drive/MyDrive/BaileyAndSoda/data/slice_7.mp3']\n",
            "drive/MyDrive/BaileyAndSoda/data/slice_0.txt transcribed!\n",
            "drive/MyDrive/BaileyAndSoda/data/slice_1.txt transcribed!\n",
            "drive/MyDrive/BaileyAndSoda/data/slice_2.txt transcribed!\n",
            "drive/MyDrive/BaileyAndSoda/data/slice_3.txt transcribed!\n",
            "drive/MyDrive/BaileyAndSoda/data/slice_4.txt transcribed!\n",
            "drive/MyDrive/BaileyAndSoda/data/slice_5.txt transcribed!\n",
            "drive/MyDrive/BaileyAndSoda/data/slice_6.txt transcribed!\n",
            "drive/MyDrive/BaileyAndSoda/data/slice_7.txt transcribed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import gradio as gr\n",
        "\n",
        "pipe = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-small\")\n",
        "\n",
        "def inference(speech_file):\n",
        "  return pipe(speech_file)[\"text\"]\n",
        "\n",
        "gr.Interface(inference,gr.Audio(type=\"filepath\"),\"text\").launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "id": "DlB9iGykTtX0",
        "outputId": "5d720be2-bcd7-4319-a595-f8c6c26e1ad5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "\n",
            "Using Embedded Colab Mode (NEW). If you have issues, please use share=True and file an issue at https://github.com/gradio-app/gradio/\n",
            "Note: opening the browser inspector may crash Embedded Colab Mode.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<gradio.routes.App at 0x7f73edf43bd0>, 'http://127.0.0.1:7860/', None)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}